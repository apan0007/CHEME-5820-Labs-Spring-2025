{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fe3c6d-09ea-4c0e-81f7-3c8454d05e77",
   "metadata": {},
   "source": [
    "# L5d: Kernelized Support Vector Machines (kSVMs)\n",
    "In this lab, we will experiment with a kernel Support Vector Machine (kSVM) to classify the non-linearly separable datasets we construct. In particular, we'll look at a kernelized version of the soft-margin support vector machine. If these terms are unfamiliar, [check out the L5c notes](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/Notes.pdf) and the review below.\n",
    "\n",
    "### Theory: Support Vector Machine (SVM)\n",
    "Suppose, we have dataset $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$, where $\\hat{\\mathbf{x}}_i \\in \\mathbb{R}^p$ is an _augmented_ feature vector ($m$ features with additional `1` to model the bias on the end of the vector) and $y_i \\in \\{-1, 1\\}$ is the corresponding class label. The goal of an SVM (for binary classification tasks) is to find the hyperplane $\\mathcal{H}(\\hat{\\mathbf{x}}) = \\{\\hat{\\mathbf{x}} \\mid \\left<\\hat{\\mathbf{x}},\\theta\\right> = 0\\}$ that separates the data points into two classes (those points above the hyperplane, and those points below the hyperplane), where $\\theta \\in \\mathbb{R}^{p}$ ($p=m+1$) is the normal vector to the hyperplane, or the parameters of the model that we need to estimate.\n",
    "* __Why another method__? Support vector machines (SVMs) and other approaches, e.g., [the perceptron](https://en.wikipedia.org/wiki/Perceptron) differ primarily in their optimization objectives and training methods: while a [perceptron](https://en.wikipedia.org/wiki/Perceptron) can find _a hyperplane_ that separates classes, SVMs seek to find the _best hyperplane_ in the sense that the _margin_ between classes is maximized.\n",
    "\n",
    "#### Soft margin\n",
    "Let's take a look at a [schematic of the ideas behind a soft margin support vector machine](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/figs/Fig-SVM-Schematic-Softmargin.pdf).\n",
    "If the data is _not linearly separable_, then we know that a perfect $\\mathcal{H}(\\hat{\\mathbf{x}})$ will not exist, i.e., \n",
    "no hyperplane will separate the data without making at least one mistake. In this case, we can estimate the _best_ hyperplane possible by solving the maximum soft margin problem given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\theta}\\quad & \\frac{1}{2}\\lVert{\\theta}\\rVert_{2}^{2} + C\\sum_{i=1}^{n}\\xi_{i}\\\\\n",
    "    \\text{subject to}\\quad & y_{i}\\left<\\hat{\\mathbf{x}}_{i},\\theta\\right> \\geq 1 - \\xi_{i}\\quad\\forall i\\\\\n",
    "    & \\xi_{i} \\geq 0\\quad\\forall i\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\xi_{i}$ is a _slack variable_, that quantifies the cost of a classification mistake, and $C>{0}$ is a user-adjustable parameter that controls the trade-off between maximizing the margin and minimizing the slack variables.\n",
    "* __Values of $C$__: If $C\\gg{1}$ the classifier will behave like the maximum (hard) margin classifier, i.e., mistakes will be expensive, and the search will avoid making choices with mistakes. However, if $C\\ll{1}$, the classifier will allow more slack (mistakes), i.e., mistakes are cheap, so what's it matter!\n",
    "\n",
    "### Tasks\n",
    "Before we start, divide into teams and familiarize yourself with the lab. Then, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (10 min)__: Let's take 10 minutes to explore how we will generate the datasets we'll explore today. We'll work through how to generate linearly separable and non-linearly separable datasets.\n",
    "* __Task 2: Linear SVM classification (15 min)__: In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `linear kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl).\n",
    "* __Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM (15 min)__: In this task, we'll perform a grid search to estimate the best hyperparameters for a keneralized SVM using the RBF kernel. We'll estimate the best $C$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "Let's get going!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef21be-0201-4515-89bb-ba8112541d8e",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070be284-e10c-4c83-90bb-4cab39d97ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be56e42-f2dd-4da0-a8df-b1bae63621eb",
   "metadata": {},
   "source": [
    "### Data\n",
    "In this section, we will build sample (binary) datasets $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$ to classify. Before we get started, we specify some constants that we use later:\n",
    "* The `number_of_points_per_label::Int` variable controls the number of sample points in the dataset for each label. The total number of instances in $\\mathcal{D}$ will be two times this number.\n",
    "* The `number_of_training_examples::Int` variable controls the number of points we use for `training`, with the balance of the instances then going to `test`.\n",
    "* The `number_of_features::Int` variable controls the number of features in the data, i.e., for $\\mathbf{x}\\in\\mathbb{R}^{m}$, this value is `m`.\n",
    "* The `ϵ::Float64` variable is a threshold value for including a not linearly separable data point into the dataset $\\mathcal{D}$, i.e., it is the probability that if we generate data that is not separable, we include it in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb75e970-d8fd-467e-8793-4122fce566ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points_per_label = 1000; # this should be 1000; number of samples per label (2 x this is the total)\n",
    "number_of_training_examples = 1600; # pick this many training examples at random\n",
    "number_of_features = 3; # we have this many features\n",
    "ϵ = 0.15; # threshold of random NLS points to accept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a6e99-99b0-44c6-9266-8c473960f782",
   "metadata": {},
   "source": [
    "Let's set up the color dictionary to visualize the classification datasets. The keys of the `my_color_dictionary::Dict Int64, RGB` dictionary class labels, i.e., $ y\\in\\{-1,1\\}$ while the values are the colors mapped to that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bf8d35-4f28-448e-aa49-4fa6ae812b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_color_dictionary = Dict{Int64,RGB}();\n",
    "my_color_dictionary[1] = colorant\"#03045e\"; # color for Label = 1\n",
    "my_color_dictionary[-1] = colorant\"#e36414\"; # color for Label = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d9e68-3fde-4b32-bf85-b34be4f508d3",
   "metadata": {},
   "source": [
    "Next, let's write a code to generate a [non-lineraly separable data set](https://en.wikipedia.org/wiki/Linear_separability) $\\mathcal{D}$ that we'll use to train (and test) our [kSVM](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels).\n",
    "\n",
    "* First, we generate a random parameter vector $\\theta\\in\\mathbb{R}^{p}$ where $p = m+1$.\n",
    "* Next, we generate (random) augmented feature vecotors $\\hat{\\mathbf{x}}\\in\\mathbb{R}^{p}$ and for specified labels, and check the $y\\cdot\\left(\\hat{\\mathbf{x}}^{\\top}\\mathbf{\\theta}\\right) \\geq 0$ condition. If this condition is true, we `accept` that data; otherwise, we `reject` the data. If we `accept` the data, we store it in the `dataset` variable, a [Set](https://docs.julialang.org/en/v1/base/collections/#Base.Set) holding a [NamedTuple type](https://docs.julialang.org/en/v1/base/base/#Core.NamedTuple), which is a mix of a tuple and a dictionary. If we `reject` the data, we roll a random number and compare it to the `ϵ::Float64` threshold value. If the random number is less than or equal to `ϵ::Float64`, we keep the rejected sample (and add it to the sample archive).\n",
    "* We keep iterating the loop until the number of elements of the `dataset` is greater than or equal to the desired number of test points specified in the `number_of_points_per_label` variable.\n",
    "\n",
    "We return the dataset $\\mathcal{D}$ in the `D::Array{Float64,2}` array, where each row is an example, each column is a feature, except for the last column, which is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4099b294-ce46-414c-98b4-69ea85e3743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000×4 Matrix{Float64}:\n",
       "  0.726233    -0.676767    -1.25183    -1.0\n",
       " -0.423925    -0.122959    -1.5469      1.0\n",
       " -0.410699     1.4107      -1.12828     1.0\n",
       " -0.572679     0.188393    -0.859837    1.0\n",
       "  1.01742     -0.31057     -0.0711871  -1.0\n",
       "  1.73155      1.32269     -0.994265    1.0\n",
       " -0.849752     0.631194    -0.409577   -1.0\n",
       "  0.100657     1.79445     -1.59855     1.0\n",
       " -0.734491    -0.647969     0.431243    1.0\n",
       "  0.0916556    1.33739      0.654012    1.0\n",
       "  0.00500934   0.18743     -0.941089    1.0\n",
       "  0.0890085    0.719732    -0.792111    1.0\n",
       " -2.13181     -1.27534      1.68331    -1.0\n",
       "  ⋮                                    \n",
       " -0.836542     0.752101    -0.208669    1.0\n",
       "  0.212219     0.00844523   0.282862   -1.0\n",
       "  2.03867      0.775547    -2.16891    -1.0\n",
       " -1.26459     -0.519193    -0.138045   -1.0\n",
       "  0.770485    -1.09878      0.407769   -1.0\n",
       "  1.60487      1.02977      1.35731     1.0\n",
       " -0.525774     0.521371    -0.638342    1.0\n",
       "  1.75444      2.17439     -0.51126     1.0\n",
       "  0.670555     1.2453      -1.42184     1.0\n",
       "  1.47396      0.496741     1.8656     -1.0\n",
       "  0.305902    -0.893306    -0.303348   -1.0\n",
       "  0.17086      0.584735    -0.0482933   1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = let\n",
    "\n",
    "    # initialize \n",
    "    dataset = Set{@NamedTuple{x::Array{Float64,1},y::Int64}}();\n",
    "    w = randn(number_of_features+1); # tmp parameters that we use to make data\n",
    "\n",
    "    # Logic to generate y = 1 samples\n",
    "    should_keep_looping = true;\n",
    "    y = 1; # label for this section\n",
    "    while (should_keep_looping == true)\n",
    "        x = randn(number_of_features) |> x -> push!(x,1); # generate a random augmented feature vector\n",
    "        \n",
    "        # check -\n",
    "        if (y*(sum(w.*x)) ≥ 0.0)\n",
    "            data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "            push!(dataset,data);\n",
    "        else\n",
    "            # failed!, Hmmmm. Should we keep this data??\n",
    "            if (rand() ≤ ϵ)\n",
    "                data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "                push!(dataset,data);\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # if we have enough examples, stop iterating\n",
    "        if (length(dataset) >= number_of_points_per_label)\n",
    "            should_keep_looping = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Logic to generate y = -1 samples\n",
    "    should_keep_looping = true;\n",
    "    y = -1; # label for this section\n",
    "    while (should_keep_looping == true)\n",
    "        x = randn(number_of_features) |> x -> push!(x,1); # generate a random augmented feature vector\n",
    "        \n",
    "        # check -\n",
    "        if (y*(sum(w.*x)) ≥ 0.0) # this is a LS point, keep\n",
    "            data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "            push!(dataset,data);\n",
    "        else\n",
    "            # failed!, Hmmmm. Should we keep this data??\n",
    "            if (rand() ≤ ϵ)\n",
    "                data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "                push!(dataset,data);\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # If we have enough examples, stop iterating\n",
    "        if (length(dataset) >= 2*number_of_points_per_label)\n",
    "            should_keep_looping = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # ok, so let's put this data into a matrix -\n",
    "    D = Array{Float64,2}(undef, 2*number_of_points_per_label, number_of_features+1);\n",
    "    for i ∈ 1:2*number_of_points_per_label\n",
    "        example = pop!(dataset);\n",
    "        feature = example.x;\n",
    "        label = example.y;\n",
    "        for j ∈ 1:number_of_features\n",
    "            D[i,j] = feature[j];\n",
    "        end\n",
    "        D[i,end] = label;\n",
    "    end\n",
    "    D\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a91da-873b-4d35-b339-4848d555c236",
   "metadata": {},
   "source": [
    "### Visualize dataset `D`\n",
    "`Unhide` the code block below to see how we plotted the dataset `D`, which contains two continuous features and a label. The color indicates the label.\n",
    "* __Summary__: We will get a different pattern of $\\pm{1}$ labels depending the `ϵ::Float64` value. The dark blue dots represent label `1`, while the orange data represents label `1`. Our classifier should be able to learn the mapping between the features and the labels for linearly separable datasets but may struggle with random outlier points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7302bcbf-7bce-4d74-9619-5889a0ca8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mVisualization disabled for more than 2 features!\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    dataset = D; # what dataset am I looking at?\n",
    "    number_of_points_to_plot = size(dataset,1);\n",
    "    if (number_of_features > 2)\n",
    "        @info \"Visualization disabled for more than 2 features!\"\n",
    "    else\n",
    "        p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "    \n",
    "        # plot label = 1\n",
    "        testlabel = 1;\n",
    "        i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "        c = my_color_dictionary[testlabel]\n",
    "        scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "    \n",
    "        # plot label = -1\n",
    "        testlabel = -1;\n",
    "        i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "        c = my_color_dictionary[testlabel]\n",
    "        scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "    \n",
    "        # plot all points\n",
    "        for i ∈ 1:number_of_points_to_plot\n",
    "            label = dataset[i,3]; # label\n",
    "            c = my_color_dictionary[label]\n",
    "            scatter!([dataset[i, 1]], [dataset[i, 2]], label=\"\", mec=:navy, c=c)\n",
    "        end\n",
    "        \n",
    "        xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "        ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa2adc-4611-442e-8d59-815186227901",
   "metadata": {},
   "source": [
    "Next, let's split that dataset `D` into `training` and `test` subsets. We do this randomly, where the `number_of_training_examples::Int64` variable specifies the number of training points. The `training::Array{Float64,2}` data will be used to estimate the model parameters, and `test::Array{Float64,2}` will be used for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a138b06c-0106-4e55-b68e-bdd561076c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = let\n",
    "\n",
    "    number_of_features = size(D,2); # number of cols of housing data\n",
    "    number_of_examples = size(D,1); # number of rows of housing data\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    training = D[training_index_set |> collect,:];\n",
    "    test = D[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    training, test\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e1edb9-34f8-484b-bbaa-cfbac629c6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400×4 Matrix{Float64}:\n",
       "  2.0913     -1.6713    -0.389584   -1.0\n",
       " -0.290164   -1.41017   -1.28377    -1.0\n",
       "  0.644935   -1.45867    0.357586    1.0\n",
       "  0.822021   -0.29376    1.20284     1.0\n",
       " -0.732021   -0.17818   -0.0391218   1.0\n",
       " -0.502414    2.08348    1.18084     1.0\n",
       " -0.527643    1.56265   -0.339418    1.0\n",
       " -0.450561   -1.16582   -0.126154   -1.0\n",
       "  0.070922   -0.291889   1.53423    -1.0\n",
       " -0.542703   -1.58048    0.175895   -1.0\n",
       "  0.571748   -1.01896    0.144533   -1.0\n",
       " -1.23547    -1.01606    0.0190175  -1.0\n",
       " -0.647029    1.46172   -1.07786     1.0\n",
       "  ⋮                                 \n",
       " -1.17978    -1.42265    1.43751    -1.0\n",
       " -0.327525    1.58613    2.05579     1.0\n",
       "  0.318132   -0.55338   -0.940889   -1.0\n",
       "  0.209971    1.22608    2.32201     1.0\n",
       " -0.836461    0.570497  -0.645633   -1.0\n",
       "  0.183515   -0.85433    0.463544   -1.0\n",
       "  1.29254     1.34889    0.0176132   1.0\n",
       "  1.09348    -2.01371    0.453748    1.0\n",
       "  0.220329    0.299432   1.4466     -1.0\n",
       "  0.0128146   0.968624  -0.753925    1.0\n",
       " -0.633849    0.364877   0.232157   -1.0\n",
       "  0.0293596  -0.137193   0.225097   -1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ff19e-5964-4fc5-90c8-0f0577ba06bc",
   "metadata": {},
   "source": [
    "## Task 2: Classification using an Linear SVM\n",
    "In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `linear kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) takes an augmented training examples matrix $\\hat{\\mathbf{X}}^{\\top}$ where the examples are on the columns and the features are the rows, and a label vector $\\mathbf{y}\\in\\left\\{-1,1\\right\\}$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns a [model instance](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) that holds the trained data and a bunch of other data associated with the problem.\n",
    "* __Hmmm__: One of the (super) interesting optional arguments [the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) is the `kernel` argument. Check out the documentation to see what kernels are supported! Wow! we get [kernelized SVM capability](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels) right out of the box. _Buy versus build, 99% buy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c5e427-8dce-47b2-a1d3-51fd7bcfbbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "WARNING: using -h 0 may be faster\n",
      "*.\n",
      "WARNING: using -h 0 may be faster\n",
      "*.\n",
      "WARNING: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 3597\n",
      "nu = 0.535511\n",
      "obj = -855.556184, rho = -0.255852\n",
      "nSV = 859, nBSV = 854\n",
      "Total nSV = 859\n"
     ]
    }
   ],
   "source": [
    "model = let\n",
    "\n",
    "    # Setup the data that we are using\n",
    "    D = training; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # TODO: Uncomment the line below to train the SVM model using the training data \n",
    "    model = svmtrain(X, y, kernel=LIBSVM.Kernel.Linear, verbose = true); # we are using the LIBSVM\n",
    "\n",
    "    # return\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc7cc9b-5cd0-46ab-9c9f-d220b48a4677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(SVC, LIBSVM.Kernel.Linear, nothing, 4, 1600, 2, [-1.0, 1.0], Int32[1, 2], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float64}, Matrix{Float64}}(859, Int32[429, 430], [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [2.69239976100081 -0.2522426227454784 … -2.2904949743433223 0.7946505263797293; 0.3769579507487846 0.21876848981869992 … -0.33003651326871875 0.4761365346118051; -0.11631806792908508 0.29665347423329447 … 1.516672133728591 0.49042110040645925; 1.0 1.0 … 1.0 1.0], Int32[1, 9, 11, 15, 18, 20, 23, 25, 35, 38  …  1574, 1575, 1577, 1582, 1583, 1584, 1589, 1592, 1594, 1600], LIBSVM.SVMNode[LIBSVM.SVMNode(1, 2.69239976100081), LIBSVM.SVMNode(1, -0.2522426227454784), LIBSVM.SVMNode(1, -0.7720629858529319), LIBSVM.SVMNode(1, -0.10109433159042229), LIBSVM.SVMNode(1, 0.06407980256377377), LIBSVM.SVMNode(1, -1.477404942569033), LIBSVM.SVMNode(1, 2.0386676107604162), LIBSVM.SVMNode(1, -0.2371294431834011), LIBSVM.SVMNode(1, -0.17988326539954497), LIBSVM.SVMNode(1, 0.560488250132751)  …  LIBSVM.SVMNode(1, 0.19585335853127817), LIBSVM.SVMNode(1, -1.40944249680796), LIBSVM.SVMNode(1, -1.3333390900007314), LIBSVM.SVMNode(1, 0.1866419232600192), LIBSVM.SVMNode(1, 1.9350486839827712), LIBSVM.SVMNode(1, 0.582678766369056), LIBSVM.SVMNode(1, -0.3272161653784253), LIBSVM.SVMNode(1, 0.0996409530167921), LIBSVM.SVMNode(1, -2.2904949743433223), LIBSVM.SVMNode(1, 0.7946505263797293)]), 0.0, [1.0; 1.0; … ; -1.0; -1.0;;], Float64[], Float64[], [-0.25585178292636385], 3, 0.25, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a40341-4c8c-4511-8a6f-814182d10735",
   "metadata": {},
   "source": [
    "__Inference__: Now that we have parameters estimated from the `training` data, we can use those parameters on the `test` dataset to see how well the model can differentiate between an actual banknote and a forgery on data it has never seen. We run the classification operation on the (unseen) test data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns the predicted label which we store in the `ŷ::Array{Int64,1}` array. We store the actual (correct) label in the `y::Array{Int64,1}` vector.\n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) also returns a second output which we save in the `decision_values` variable. __Hmmmm__. Not sure what these values are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b42d7969-9bfa-4f4f-98fb-ea9443c11eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ,y,d = let\n",
    "\n",
    "     # Setup the data that we are using\n",
    "    D = test; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "    \n",
    "    # TODO: Uncomment the line below to test the SVM model on the other block of the data.\n",
    "    ŷ, decision_values = svmpredict(model, X);\n",
    "\n",
    "    # return -\n",
    "    ŷ,y,decision_values\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea4db2-103c-4e8f-b858-96dd1fb66db5",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Finally, let's compute the confusion matrix. The confusion matrix is a $2\\times{2}$ matrix that contains four entries: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). [Click me for a confusion matrix schematic!](https://github.com/varnerlab/CHEME-5820-Labs-Spring-2025/blob/main/labs/week-3/L3b/figs/Fig-BinaryConfusionMatrix.pdf). Let's compute these four values [using the `confusion(...)` method](src/Compute.jl) and store them in the `CM::Array{Int64,2}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d57ea7ec-1fd8-41cf-9d4d-e85768e10d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 169   42\n",
       "  35  154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM = confusion(y, ŷ) # call with the SVM test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52750870-9c80-4e72-8dfa-6761ba710171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction correct: 0.8075 Fraction incorrect 0.1925\n"
     ]
    }
   ],
   "source": [
    "number_of_test_points = length(y);\n",
    "correct_prediction_perceptron = CM[1,1] + CM[2,2];\n",
    "(correct_prediction_perceptron/number_of_test_points) |> f-> println(\"Fraction correct: $(f) Fraction incorrect $(1-f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a9218-6a6a-4ca4-b6c1-e107d8e2d083",
   "metadata": {},
   "source": [
    "### DQs \n",
    "Before we move to task 3, let's explore a few issues. [This may be handy](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf) or [maybe this?](https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)\n",
    "1. Are we solving the `hard` or the `soft` margin problem?\n",
    "2. What are all the fields inside the `model` instance, and what do they mean? Let's [check out the code, and see what we see!](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl)\n",
    "3. What are the `decision_values` that are returned from the [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) (we saved these in the `d` variable)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbfd488a-746f-45d8-891c-5b4696d490bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×400 Matrix{Float64}:\n",
       " 2.61666  2.10371  2.59351  1.00887  …  -1.47393  -0.205698  0.533029\n",
       " 0.0      0.0      0.0      0.0          0.0       0.0       0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e2021-5686-473e-8f6b-a4508bb14a31",
   "metadata": {},
   "source": [
    "## Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM\n",
    "In this task, we'll perform a grid search to estimate the best hyperparameters for a keneralized SVM using the RBF kernel. We'll estimate the best $C$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "[A grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search) for kernel SVM parameters C and $\\gamma$ involves systematically exploring combinations of these hyperparameters to find the optimal configuration for model performance. Here's a description of the process:\n",
    "* __Define parameter ranges__. For the cost parameter $C$, we use $C\\in\\left\\{2^{-5},2^{-3},\\dots,2^{15}\\right\\}$ while for the length scale parameter $\\gamma$, we use $\\gamma\\in\\left\\{2^{-15},2^{-13},\\dots,2^{3}\\right\\}$. We store the exponents of these ranges in the `α::Array{Float64,1}` and `β::Array{Float64,1}` arrays, respectively.\n",
    "* __Model training and evaluation__: For each parameter combination $(C_{i},\\gamma_{j})$ we train a SVM model with a RBF kernel, compute the confusion matrix and then evaluate the prediction accuracy. We save the accuracy data in the `A::Array{Float64,2}` array, where $a_{ij}\\in\\mathbf{A}$ holds the accuracy values for the parameter combination $(C_{i},\\gamma_{j})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "916a6ac0-a18f-4b0e-9aa5-dda1e0fa7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: reaching max number of iterations\n",
      "\n",
      "WARNING: reaching max number of iterations\n"
     ]
    }
   ],
   "source": [
    "A, α, β = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "    \n",
    "    α = range(-5,stop = 15, step=2) |> collect; # exponent for C -\n",
    "    β = range(-15,stop = 3, step=2) |> collect; # exponent for γ -\n",
    "    number_of_points_C = length(α);\n",
    "    number_of_points_gamma = length(β);\n",
    "    accuracy = Array{Float64,2}(undef, number_of_points_C, number_of_points_gamma);\n",
    "    \n",
    "    for i ∈ eachindex(α)\n",
    "        C = 2.0^α[i];\n",
    "        for j ∈ eachindex(β)\n",
    "            γ = 2.0^β[j];\n",
    "\n",
    "            # TODO: Uncomment below to train the mode in the (C,γ) values -\n",
    "            ŷ₂,_ = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                verbose = false, cost = C, gamma = γ) |> model -> svmpredict(model,X₂);\n",
    "\n",
    "            # how many mistakes?\n",
    "            accuracy[i,j] = confusion(y₂, ŷ₂) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/number_of_test_examples;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    accuracy, α, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfccd256-16f9-4a9f-a649-f25f161fdb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABuCAAAAAD0EunuAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAUdJREFUaAW9wbFtHEEURMH3994BUoiKiLFQAANQWPK5M7T6nBEIWV3lG//nD/GX2MTi9IuQAimQAimQAimQAimQAvnWB3Fz2sRNDPFBSIEUSIEUSIEUSIEUSIH8w29OQ9ycLk6LkAIpkAIpkAIpkAIpkAJ5eSeGGOImNqdNPAgJKZACKZACKZACKZACKfCdGGKIxWmImxhiiB+EFEiBFEiBFEiBFEiBFDjEEIsY4pOQGOIiJJ6EFEiBFEiBFEiBFEiBFDjEIoa4iQffGeIncRFSIAVSIAVSIAVSIAVS4CKG2MQiLuKT04N4Ek9CCqRACqRACqRACqRAChxOixjiIjaxiQenTUiBFEiBFEiBFEiBFEiBvGxiERcxnC7iQQwnKZACKZACKZACKZACKZCXRQwxxCaGuIiLGE5SIAVSIAVSIAVSIAVS8AUagCPHps0bnQAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABuCAAAAAD0EunuAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAUdJREFUaAW9wbFtHEEURMH3994BUoiKiLFQAANQWPK5M7T6nBEIWV3lG//nD/GX2MTi9IuQAimQAimQAimQAimQAvnWB3Fz2sRNDPFBSIEUSIEUSIEUSIEUSIH8w29OQ9ycLk6LkAIpkAIpkAIpkAIpkAJ5eSeGGOImNqdNPAgJKZACKZACKZACKZACKfCdGGKIxWmImxhiiB+EFEiBFEiBFEiBFEiBFDjEEIsY4pOQGOIiJJ6EFEiBFEiBFEiBFEiBFDjEIoa4iQffGeIncRFSIAVSIAVSIAVSIAVS4CKG2MQiLuKT04N4Ek9CCqRACqRACqRACqRAChxOixjiIjaxiQenTUiBFEiBFEiBFEiBFEiBvGxiERcxnC7iQQwnKZACKZACKZACKZACKZCXRQwxxCaGuIiLGE5SIAVSIAVSIAVSIAVS8AUagCPHps0bnQAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "11×10 Matrix{Gray{Float64}}:\n",
       " 0.5275  0.5275  0.5275  0.5275  0.2525  …  0.1875  0.18    0.18    0.5275\n",
       " 0.5275  0.5275  0.5275  0.205   0.1925     0.185   0.17    0.1725  0.205\n",
       " 0.5275  0.5275  0.1925  0.1925  0.195      0.185   0.175   0.175   0.195\n",
       " 0.5275  0.19    0.1925  0.195   0.185      0.18    0.1725  0.1825  0.2125\n",
       " 0.1875  0.1925  0.195   0.1875  0.185      0.1725  0.1775  0.19    0.245\n",
       " 0.1925  0.1975  0.1875  0.1925  0.1725  …  0.175   0.1825  0.205   0.2625\n",
       " 0.1975  0.1875  0.1925  0.18    0.1825     0.175   0.1875  0.24    0.27\n",
       " 0.1875  0.1925  0.19    0.1725  0.18       0.1675  0.1875  0.26    0.29\n",
       " 0.1925  0.1925  0.18    0.1775  0.1875     0.1725  0.2     0.2575  0.2875\n",
       " 0.1925  0.19    0.1725  0.18    0.1925     0.18    0.2125  0.2625  0.2875\n",
       " 0.1925  0.18    0.175   0.1825  0.19    …  0.1875  0.22    0.265   0.2875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gray.(1 .- A) # fun! More accurate parameter combinations are darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "476dbf34-3f9d-482e-a389-46b0325d6872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11×10 Matrix{Float64}:\n",
       " 0.4725  0.4725  0.4725  0.4725  0.7475  …  0.8125  0.82    0.82    0.4725\n",
       " 0.4725  0.4725  0.4725  0.795   0.8075     0.815   0.83    0.8275  0.795\n",
       " 0.4725  0.4725  0.8075  0.8075  0.805      0.815   0.825   0.825   0.805\n",
       " 0.4725  0.81    0.8075  0.805   0.815      0.82    0.8275  0.8175  0.7875\n",
       " 0.8125  0.8075  0.805   0.8125  0.815      0.8275  0.8225  0.81    0.755\n",
       " 0.8075  0.8025  0.8125  0.8075  0.8275  …  0.825   0.8175  0.795   0.7375\n",
       " 0.8025  0.8125  0.8075  0.82    0.8175     0.825   0.8125  0.76    0.73\n",
       " 0.8125  0.8075  0.81    0.8275  0.82       0.8325  0.8125  0.74    0.71\n",
       " 0.8075  0.8075  0.82    0.8225  0.8125     0.8275  0.8     0.7425  0.7125\n",
       " 0.8075  0.81    0.8275  0.82    0.8075     0.82    0.7875  0.7375  0.7125\n",
       " 0.8075  0.82    0.825   0.8175  0.81    …  0.8125  0.78    0.735   0.7125"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A # rows are C, cols are γ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00c9e8-1f2c-4e93-b766-cd6b634ae35d",
   "metadata": {},
   "source": [
    "### What is the best SVM model?\n",
    "Let's find the model with the highest training accuracy. We'll call this the _best model_ and save it in the `best_model::LIBSVM.SVM` variable. First, which element of the accuracy matrix $\\mathbf{A}$ holds the maximum?\n",
    "* We can estimate maximum accuracy element of the matrix $\\mathbf{A}$ [using the `maximum(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.maximum). The `(i,j)` position of the maximum element can be computed using [the `argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax). The [`argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax) returns a cool data structure [called a `CartesianIndex`](https://docs.julialang.org/en/v1/base/arrays/#Base.IteratorsMD.CartesianIndex) which holds the (`row, col`) values of the maximum. This data structure is a way to model collection indices (which seems interesting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b7cb67f-dcaa-4fcd-a800-389d8b580625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "coordinate = argmax(A)\n",
    "best_accuracy = maximum(A)\n",
    "println(\"Best test accuracy: $(best_accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1269ae-8a2f-4720-8b23-d96b06198aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CartesianIndex(8, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f19ea-d180-491e-bde0-6092861dac79",
   "metadata": {},
   "source": [
    "Next, get the best parameters, and save these in the `C_best::Float64` and `γ_best::Float64` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab4c8dd4-b872-413b-852c-4f0e578bdfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512.0, 0.03125)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_best, γ_best = let\n",
    "    \n",
    "    C = coordinate[1] |> i-> α[i] |> e-> 2.0^e; # Wow! we grab the row (corresponds to C), get the exponent from α, and then compute the value\n",
    "    γ = coordinate[2] |> i-> β[i] |> e-> 2.0^e; # Nice! grab the col (corresponds to γ), get the exponent from β, and then compute the value\n",
    "\n",
    "    C,γ\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db671b-1b5a-4afb-990e-3ce8bd784158",
   "metadata": {},
   "source": [
    "Finally, estimate the `best_model::LIBSVM.SVM`, the best predicted label vector `ŷ_test_best::Array{Int64,1}`, and the actual label vector `y_test::Array{Int64,1}` using the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a16e8e86-49ee-41e9-b935-f8fce18f882e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "best_model, ŷ_test_best, y_test = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # estimate the best model -\n",
    "    best_model = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                    verbose = false, cost = C_best, gamma = γ_best)\n",
    "    \n",
    "\n",
    "    # compute the ŷ_best -\n",
    "    ŷ_best, _ = svmpredict(best_model,X₂);\n",
    "\n",
    "    # return -\n",
    "    best_model, ŷ_best, y₂\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da36dd-5158-4179-92db-22685d733c49",
   "metadata": {},
   "source": [
    "Confirm the accuracy of the `best_model::LIBSVM.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81cb4bb2-606f-466f-a8ca-bc03112e9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_best_confirm = confusion(y_test, ŷ_test_best) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/size(test,1) # impressive!\n",
    "@assert best_accuracy == accuracy_best_confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3af624-e89b-4ff6-b8e5-e5c2a8e8c367",
   "metadata": {},
   "source": [
    "### DQs\n",
    "1. What factors influence the prediction accuracy of the kSVM? For example, do the number of features influence performance or the fraction of random points? Let's run a few cases with different parameters and develop some intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee974d-d33b-473e-8d2a-088691db4dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
